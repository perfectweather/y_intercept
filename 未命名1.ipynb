{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "137b9509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset</th>\n",
       "      <th>date</th>\n",
       "      <th>lastprice</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1332 JT</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>169.0987</td>\n",
       "      <td>1464100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1332 JT</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>166.3266</td>\n",
       "      <td>1783500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1332 JT</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>166.3266</td>\n",
       "      <td>1759800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1332 JT</td>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>165.4026</td>\n",
       "      <td>767800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1332 JT</td>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>167.2507</td>\n",
       "      <td>1503100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451108</th>\n",
       "      <td>9984 JT</td>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>10370.0000</td>\n",
       "      <td>12041200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451109</th>\n",
       "      <td>9984 JT</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>10620.0000</td>\n",
       "      <td>11346000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451110</th>\n",
       "      <td>9984 JT</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>10400.0000</td>\n",
       "      <td>9771000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451111</th>\n",
       "      <td>9984 JT</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>10220.0000</td>\n",
       "      <td>13941600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451112</th>\n",
       "      <td>9984 JT</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>9969.0000</td>\n",
       "      <td>20715700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451113 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          asset       date   lastprice    volume\n",
       "0       1332 JT 2013-01-04    169.0987   1464100\n",
       "1       1332 JT 2013-01-07    166.3266   1783500\n",
       "2       1332 JT 2013-01-08    166.3266   1759800\n",
       "3       1332 JT 2013-01-09    165.4026    767800\n",
       "4       1332 JT 2013-01-10    167.2507   1503100\n",
       "...         ...        ...         ...       ...\n",
       "451108  9984 JT 2021-03-15  10370.0000  12041200\n",
       "451109  9984 JT 2021-03-16  10620.0000  11346000\n",
       "451110  9984 JT 2021-03-17  10400.0000   9771000\n",
       "451111  9984 JT 2021-03-18  10220.0000  13941600\n",
       "451112  9984 JT 2021-03-19   9969.0000  20715700\n",
       "\n",
       "[451113 rows x 4 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso,LassoCV,LassoLarsCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from datetime import datetime\n",
    "\n",
    "df = pd.read_csv('/Users/zhou/Downloads/data_y.csv',header = 0, names= [\"asset\",\"date\",'lastprice','volume'])\n",
    "asset_series = df['asset'].unique()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "date_list = df['date'].unique()\n",
    "date_list.sort()\n",
    "last_date = df.date.iloc[-1]\n",
    "begin_date = df.date.iloc[0]\n",
    "df_org = df.set_index(['asset','date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b51802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2791395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b0704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "17f1e210",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3720253323.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/3720253323.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def asset_list(index): \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4ed134d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_asset(asset,df,trade_date):\n",
    "#     df = pd.read_csv(index[i],header = 0, names= [\"number\",\"date\",'high','lastprice','low','open','close','time','value','volume'])\n",
    "    df['log1d']= pd.DataFrame(np.log(df.lastprice/df.lastprice.shift(1)))\n",
    "    df['log2d']= pd.DataFrame(np.log(df.lastprice/df.lastprice.shift(2)))\n",
    "    df['log3d']= pd.DataFrame(np.log(df.lastprice/df.lastprice.shift(3)))\n",
    "    df['log5d']= pd.DataFrame(np.log(df.lastprice/df.lastprice.shift(5)))\n",
    "    df['log10d']= pd.DataFrame(np.log(df.lastprice/df.lastprice.shift(10)))\n",
    "    df['log20d']= pd.DataFrame(np.log(df.lastprice/df.lastprice.shift(20)))\n",
    "    df['log30d']= pd.DataFrame(np.log(df.lastprice/df.lastprice.shift(30)))\n",
    "    df['log60d']= pd.DataFrame(np.log(df.lastprice/df.lastprice.shift(60)))\n",
    "        # ma_list = [5, 10, 20,30,40]\n",
    "        # # 计算简单算术移动平均线MA - 注意：stock_data['close']为股票每天的收盘价\n",
    "        # for ma in ma_list:\n",
    "        #     df['ma' + str(ma*3)+'s'] = df['lastprice'].rolling(window=ma).mean()\n",
    "        #     df['std' + str(ma*3)+'s'] = df['lastprice'].rolling(window=ma).std()\n",
    "            #pd.rolling_mean(df.lastprice, ma)\n",
    "\n",
    "        # for i in range(40,len(df.lastprice)):\n",
    "        #     df['ma15s'].iloc[i] = np.mean(df['lastprice'].iloc[i-4:i+1])/df.lastprice.iloc[i] \n",
    "        #     df['ma30s'].iloc[i] = pd.DataFrame(np.mean(df['lastprice'].iloc[i-9:i+1])/df.lastprice.iloc[i])\n",
    "        #     df['ma60s'].iloc[i] = np.mean(df['lastprice'].iloc[i-19:i+1])/df.lastprice.iloc[i]\n",
    "        #     df['ma90s'].iloc[i] = pd.DataFrame(np.mean(df['lastprice'].iloc[i-29:i+1])/df.lastprice.iloc[i])  \n",
    "        #     df['ma120s'].iloc[i] = pd.DataFrame(np.mean(df['lastprice'].iloc[i-39:i+1])/df.lastprice.iloc[i])\n",
    "        #     df['v30s'].iloc[i] = pd.DataFrame(np.std(df['lastprice'].iloc[i-9:i+1]))\n",
    "        #     df['v60s'].iloc[i] = pd.DataFrame(np.std(df['lastprice'].iloc[i-19:i+1]))\n",
    "        #     df['v90s'].iloc[i] = pd.DataFrame(np.std(df['lastprice'].iloc[i-29:i+1]))\n",
    "        #     df['v120s'].iloc[i] = pd.DataFrame(np.std(df['lastprice'].iloc[i-39:i+1]))      \n",
    "    df['volume1d'] = df['volume']- df['volume'].shift(1)\n",
    "    df['volume2d'] = df['volume']- df['volume'].shift(2)\n",
    "    df['volume3d'] = df['volume']- df['volume'].shift(3)\n",
    "    \n",
    "    df['volume5d'] = df['volume']- df['volume'].shift(5)\n",
    "    df['volume10d'] = df['volume']-df['volume'].shift(10)\n",
    "    df['volume20d'] = df['volume']-df['volume'].shift(20)\n",
    "    df['volume30d'] = df['volume']-df['volume'].shift(30)\n",
    "    df['volume60d'] = df['volume']-df['volume'].shift(60)\n",
    "    df['y'] = pd.DataFrame(np.log(df.lastprice.shift(-20)/df.lastprice))\n",
    "\n",
    "    df_feature_pd = df[['lastprice','volume','log1d','log2d','log3d','log5d','log10d','log20d','log30d','log60d',\n",
    "                      'volume1d','volume2d','volume3d','volume5d','volume10d','volume20d','volume30d','volume60d']]\n",
    "#         df_feature_pd_witht = df[['lastprice','volume','log1d','log2d','log3d','log5d','log10d','log20d','log30d','log60d',\n",
    "#                       'volume1d','volume2d','volume3d','volume5d','volume10d','volume20d','volume30d','volume60d']]\n",
    "#         #df_feature_pd = df[['high','lastprice','low','open','close','volume','log3s','log6s','log9s','log15s','log30s','log60s','log90s','log120s',\n",
    "#         #              'ma15s','ma30s','ma60s','ma90s','ma120s','std30s','std60s','std90s','std120s','(high-lastprice)/open','(lastprice-low)/open','low/open','high/open','(open-close)/close']]\n",
    "    df_feature_train_pd = df_feature_pd[df.index <= trade_date].iloc[60::]\n",
    "    df_feature_test_pd = df_feature_pd[df.index > trade_date].iloc[::-1].iloc[20::].iloc[::-1]\n",
    "#         df_feature_train_pd_witht = df_feature_pd_witht[df.date <= '03/26/2019'].iloc[40::]\n",
    "#         df_feature_test_pd_witht = df_feature_pd_witht[df.date > '03/26/2019'].iloc[::-1].iloc[20::].iloc[::-1]\n",
    "#         train_xset_list.append(df_feature_train_pd_witht)\n",
    "#         test_xset_list.append(df_feature_test_pd_witht)\n",
    "    df_feature_train = df_feature_train_pd.values\n",
    "    df_feature_test = df_feature_test_pd.values\n",
    "    df_feature = df_feature_pd.values\n",
    "    new_df_feature_train=df_feature_train/np.max(df_feature_train,axis = 0)\n",
    "    #new_df_feature_test=df_feature_test_pd/np.max(df_feature_train_pd,axis = 0)\n",
    "    new_df_feature_test=df_feature_test/np.max(df_feature_test,axis = 0)\n",
    "        #arr_mean_y = np.mean(df_y) #求均值\n",
    "        #arr_std_y = np.std(df_y,ddof=1) #求标准差\n",
    "        #new_df_y=(df_y-arr_mean_y )/arr_std_y\n",
    "    df_y_train = df['y'][df.index <= trade_date].iloc[60::]\n",
    "#     df_y_test = df['y'][df.index > trade_date].iloc[::-1].iloc[20::].iloc[::-1]\n",
    "#         df_y_train_witht = df[['y','date','time']][df.date <= '12/31/2020'].iloc[40::]\n",
    "#         df_y_test_witht = df[['y','date','time']][df.date > '12/31/2020'].iloc[::-1].iloc[20::].iloc[::-1]\n",
    "#         train_yset_list.append(df_y_train_witht) \n",
    "#         test_yset_list.append(df_y_test_witht)\n",
    "    df_y_train = df_y_train.values\n",
    "#     df_y_test = df_y_test.values\n",
    "    new_df_y_train = df_y_train/np.max(df_y_train,axis = 0)\n",
    "    #new_df_y_test = df_y_test/np.max(df_y_train,axis = 0)\n",
    "#     new_df_y_test = df_y_test/np.max(df_y_test,axis = 0)\n",
    "\n",
    "\n",
    "        # a = np.sort(new_df_y_train)\n",
    "        # b = np.array(new_df_y_train)\n",
    "        # for i in range(len(new_df_y_train)):\n",
    "        #     b[i] = (i+1) / len(new_df_y_train)\n",
    "        # print(a[int(len(new_df_y_train)*0.3)])\n",
    "        # print(a[int(len(new_df_y_train)*0.7)])\n",
    "        # plt.plot(a,b)\n",
    "        # model = LassoCV()  # LassoCV自动调节alpha可以实现选择最佳的alpha。\n",
    "        # #model = LassoLarsCV()  # LassoLarsCV自动调节alpha可以实现选择最佳的alpha\n",
    "        # model.fit(new_df_feature_train,new_df_y_train)   # 线性回归建模\n",
    "        # print('系数矩阵:\\n',model.coef_)\n",
    "        # #print('线性回归模型:\\n',model)\n",
    "        # #print('最佳的alpha：',model.alpha_) \n",
    "        # atest = np.sort(new_df_y_test)\n",
    "        #print(atest[int(len(new_df_y_test)*0.3)])\n",
    "        #print(atest[int(len(new_df_y_test)*0.7)])\n",
    "#         df_feature_Lasso_pd_witht = df[[\"date\",\"time\",'high','lastprice','volume','log3s','log6s','log9s','log15s','log30s','log60s','log90s','log120s',\n",
    "#                       '(high-lastprice)/open','(lastprice-low)/open','(open-close)/close']]\n",
    "        #random forest test\n",
    "#         bool_series = new_df_y_train > 0.005\n",
    "#         #print(new_df_y_train.size)\n",
    "#         y_train = pd.Series(np.zeros(new_df_y_train.size))\n",
    "#         #bool_series.index = y_train.index\n",
    "#         y_train[bool_series] = 1\n",
    "#         bool_series = (new_df_y_train) < -0.005\n",
    "#         #bool_series.index = y_train.index\n",
    "#         y_train[bool_series] = -1\n",
    "\n",
    "#         bool_series = (new_df_y_test) > 0.005\n",
    "#         y_test = pd.Series(np.zeros(new_df_y_test.size))\n",
    "#         #bool_series.index = y_test.index\n",
    "#         #y = 0\n",
    "#         y_test[bool_series] = 1\n",
    "#         bool_series = (new_df_y_test) < -0.005\n",
    "#         #bool_series.index = y_test.index\n",
    "#         y_test[bool_series] = -1\n",
    "#         train_yset_01_list.append(pd.DataFrame(y_train))\n",
    "#         test_yset__01_list.append(pd.DataFrame(y_test))\n",
    "        #print(y[100:900])\n",
    "    clf = RandomForestRegressor(n_estimators=10, max_depth=None,min_samples_split=2, random_state=0)\n",
    "    clf.fit(new_df_feature_train, df_y_train, sample_weight=None)  \n",
    "    scores = cross_val_score(clf, new_df_feature_train, df_y_train,cv=10)\n",
    "#     score_train_list.append(clf.score(new_df_feature_train, df_y_train))\n",
    "#     score_test_list.append(clf.score(new_df_feature_test, df_y_test))\n",
    "#     scores_list.append(scores.mean())\n",
    "            #print(clf.feature_importances_)\n",
    "            #print(clf.score(new_df_feature_train, y_train))  \n",
    "            #print(clf.score(new_df_feature_test, y_test))\n",
    "        \n",
    "            # clf = ExtraTreesClassifier(n_estimators=10, max_depth=None,min_samples_split=2, random_state=0)\n",
    "            # scores = cross_val_score(clf, new_df_feature, y)\n",
    "            #print(scores.mean())\n",
    "    predictions = clf.predict(new_df_feature_test)\n",
    "    predictions = pd.DataFrame(predictions,index = df_feature_test_pd.index)\n",
    "    price = pd.DataFrame(df_feature_test_pd.lastprice,index = df_feature_test_pd.index)\n",
    "#     predictions_list.append(predictions)\n",
    "    return predictions,scores,price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d288061a",
   "metadata": {},
   "source": [
    "Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "47e1c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime('01/01/2021')\n",
    "rebalance_period = 20  # 20天换仓\n",
    "transaction_cost = 0.001  # 交易费为万分之10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ee9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb8118f3",
   "metadata": {},
   "source": [
    "Training: Use random forest to predict. Here, the trading frequancy is 20 trading days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6efea",
   "metadata": {},
   "source": [
    "One: traning is not adaptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b7a8e0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pre_test[i] = predictions\n",
      "/var/folders/50/85gxfbhs1lg3qzr_1ddn62n80000gn/T/ipykernel_67415/300010092.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  price_test[i] = price\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1332 JT</th>\n",
       "      <th>1605 JT</th>\n",
       "      <th>1721 JT</th>\n",
       "      <th>1801 JT</th>\n",
       "      <th>1802 JT</th>\n",
       "      <th>1803 JT</th>\n",
       "      <th>1812 JT</th>\n",
       "      <th>1925 JT</th>\n",
       "      <th>1928 JT</th>\n",
       "      <th>1963 JT</th>\n",
       "      <th>...</th>\n",
       "      <th>9502 JT</th>\n",
       "      <th>9503 JT</th>\n",
       "      <th>9531 JT</th>\n",
       "      <th>9532 JT</th>\n",
       "      <th>9602 JT</th>\n",
       "      <th>9613 JT</th>\n",
       "      <th>9735 JT</th>\n",
       "      <th>9766 JT</th>\n",
       "      <th>9983 JT</th>\n",
       "      <th>9984 JT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>-0.018939</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>-0.027378</td>\n",
       "      <td>-0.075030</td>\n",
       "      <td>-0.116087</td>\n",
       "      <td>-0.026987</td>\n",
       "      <td>0.011689</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>-0.026465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020225</td>\n",
       "      <td>-0.013980</td>\n",
       "      <td>-0.082601</td>\n",
       "      <td>-0.046481</td>\n",
       "      <td>0.030419</td>\n",
       "      <td>-0.002494</td>\n",
       "      <td>0.041968</td>\n",
       "      <td>-0.069077</td>\n",
       "      <td>-0.136032</td>\n",
       "      <td>0.029471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>0.002930</td>\n",
       "      <td>-0.006106</td>\n",
       "      <td>-0.060357</td>\n",
       "      <td>-0.029978</td>\n",
       "      <td>-0.110961</td>\n",
       "      <td>-0.036406</td>\n",
       "      <td>-0.065880</td>\n",
       "      <td>0.018989</td>\n",
       "      <td>-0.055861</td>\n",
       "      <td>-0.028884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025202</td>\n",
       "      <td>-0.020319</td>\n",
       "      <td>-0.077105</td>\n",
       "      <td>-0.043631</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.024940</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.066285</td>\n",
       "      <td>-0.135481</td>\n",
       "      <td>0.039391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>-0.062118</td>\n",
       "      <td>-0.055911</td>\n",
       "      <td>-0.060585</td>\n",
       "      <td>-0.039414</td>\n",
       "      <td>-0.122187</td>\n",
       "      <td>-0.115944</td>\n",
       "      <td>0.006131</td>\n",
       "      <td>0.010083</td>\n",
       "      <td>-0.010172</td>\n",
       "      <td>-0.010369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010587</td>\n",
       "      <td>-0.032077</td>\n",
       "      <td>-0.097532</td>\n",
       "      <td>-0.049600</td>\n",
       "      <td>0.005532</td>\n",
       "      <td>0.060582</td>\n",
       "      <td>0.033660</td>\n",
       "      <td>-0.048928</td>\n",
       "      <td>-0.029593</td>\n",
       "      <td>0.058375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>-0.040547</td>\n",
       "      <td>-0.035640</td>\n",
       "      <td>-0.047727</td>\n",
       "      <td>-0.068679</td>\n",
       "      <td>-0.090097</td>\n",
       "      <td>-0.146940</td>\n",
       "      <td>-0.046812</td>\n",
       "      <td>-0.033392</td>\n",
       "      <td>-0.010785</td>\n",
       "      <td>0.036078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022524</td>\n",
       "      <td>-0.044527</td>\n",
       "      <td>-0.084286</td>\n",
       "      <td>-0.060937</td>\n",
       "      <td>0.013477</td>\n",
       "      <td>-0.064922</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>-0.024479</td>\n",
       "      <td>-0.072134</td>\n",
       "      <td>0.067698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>0.011170</td>\n",
       "      <td>-0.031788</td>\n",
       "      <td>-0.045364</td>\n",
       "      <td>-0.153280</td>\n",
       "      <td>-0.111649</td>\n",
       "      <td>-0.147236</td>\n",
       "      <td>-0.055404</td>\n",
       "      <td>-0.003504</td>\n",
       "      <td>-0.009088</td>\n",
       "      <td>0.070912</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048316</td>\n",
       "      <td>-0.057901</td>\n",
       "      <td>-0.122016</td>\n",
       "      <td>-0.056297</td>\n",
       "      <td>-0.044304</td>\n",
       "      <td>-0.050745</td>\n",
       "      <td>-0.012803</td>\n",
       "      <td>0.023852</td>\n",
       "      <td>-0.167594</td>\n",
       "      <td>0.066568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-12</th>\n",
       "      <td>0.018327</td>\n",
       "      <td>-0.054434</td>\n",
       "      <td>-0.033760</td>\n",
       "      <td>-0.145032</td>\n",
       "      <td>-0.101840</td>\n",
       "      <td>-0.138109</td>\n",
       "      <td>-0.054515</td>\n",
       "      <td>-0.062608</td>\n",
       "      <td>-0.001871</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097554</td>\n",
       "      <td>-0.076369</td>\n",
       "      <td>-0.094036</td>\n",
       "      <td>-0.110846</td>\n",
       "      <td>0.062038</td>\n",
       "      <td>-0.051137</td>\n",
       "      <td>-0.002323</td>\n",
       "      <td>0.061398</td>\n",
       "      <td>-0.069977</td>\n",
       "      <td>-0.015520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>0.025242</td>\n",
       "      <td>-0.045809</td>\n",
       "      <td>-0.022087</td>\n",
       "      <td>-0.121981</td>\n",
       "      <td>-0.102348</td>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.046977</td>\n",
       "      <td>-0.059349</td>\n",
       "      <td>-0.002847</td>\n",
       "      <td>0.033383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072513</td>\n",
       "      <td>-0.048337</td>\n",
       "      <td>-0.096683</td>\n",
       "      <td>-0.045818</td>\n",
       "      <td>-0.010623</td>\n",
       "      <td>-0.101832</td>\n",
       "      <td>-0.023574</td>\n",
       "      <td>0.081042</td>\n",
       "      <td>-0.126414</td>\n",
       "      <td>0.026531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-14</th>\n",
       "      <td>-0.001391</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>-0.049412</td>\n",
       "      <td>-0.137831</td>\n",
       "      <td>-0.038430</td>\n",
       "      <td>-0.112005</td>\n",
       "      <td>-0.047107</td>\n",
       "      <td>-0.034325</td>\n",
       "      <td>-0.071045</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060910</td>\n",
       "      <td>-0.060857</td>\n",
       "      <td>-0.098281</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>-0.020077</td>\n",
       "      <td>-0.073202</td>\n",
       "      <td>-0.027342</td>\n",
       "      <td>0.064923</td>\n",
       "      <td>-0.144499</td>\n",
       "      <td>-0.050415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>-0.016707</td>\n",
       "      <td>-0.095565</td>\n",
       "      <td>-0.025274</td>\n",
       "      <td>-0.133647</td>\n",
       "      <td>-0.071924</td>\n",
       "      <td>-0.114405</td>\n",
       "      <td>-0.044122</td>\n",
       "      <td>-0.049489</td>\n",
       "      <td>-0.034384</td>\n",
       "      <td>0.015962</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079636</td>\n",
       "      <td>-0.090742</td>\n",
       "      <td>-0.028470</td>\n",
       "      <td>-0.013592</td>\n",
       "      <td>-0.023055</td>\n",
       "      <td>-0.038585</td>\n",
       "      <td>-0.023277</td>\n",
       "      <td>0.029088</td>\n",
       "      <td>0.041788</td>\n",
       "      <td>0.002161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-18</th>\n",
       "      <td>-0.078730</td>\n",
       "      <td>-0.018462</td>\n",
       "      <td>-0.007623</td>\n",
       "      <td>-0.056069</td>\n",
       "      <td>-0.105540</td>\n",
       "      <td>-0.149555</td>\n",
       "      <td>-0.061788</td>\n",
       "      <td>-0.102335</td>\n",
       "      <td>-0.090226</td>\n",
       "      <td>0.036020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068695</td>\n",
       "      <td>-0.050981</td>\n",
       "      <td>-0.089447</td>\n",
       "      <td>-0.035517</td>\n",
       "      <td>-0.062368</td>\n",
       "      <td>0.018416</td>\n",
       "      <td>-0.059141</td>\n",
       "      <td>-0.012667</td>\n",
       "      <td>0.071853</td>\n",
       "      <td>0.056997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-19</th>\n",
       "      <td>-0.041826</td>\n",
       "      <td>-0.029179</td>\n",
       "      <td>-0.010371</td>\n",
       "      <td>-0.032611</td>\n",
       "      <td>-0.093590</td>\n",
       "      <td>-0.106185</td>\n",
       "      <td>-0.035366</td>\n",
       "      <td>-0.040441</td>\n",
       "      <td>-0.077071</td>\n",
       "      <td>-0.069582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062940</td>\n",
       "      <td>-0.065383</td>\n",
       "      <td>-0.166454</td>\n",
       "      <td>-0.002429</td>\n",
       "      <td>-0.059364</td>\n",
       "      <td>-0.027810</td>\n",
       "      <td>-0.049476</td>\n",
       "      <td>-0.026287</td>\n",
       "      <td>-0.056048</td>\n",
       "      <td>-0.095529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-20</th>\n",
       "      <td>-0.073261</td>\n",
       "      <td>-0.078500</td>\n",
       "      <td>-0.015295</td>\n",
       "      <td>-0.044377</td>\n",
       "      <td>-0.093502</td>\n",
       "      <td>-0.084237</td>\n",
       "      <td>-0.053176</td>\n",
       "      <td>0.012432</td>\n",
       "      <td>-0.045632</td>\n",
       "      <td>-0.066411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113420</td>\n",
       "      <td>-0.043629</td>\n",
       "      <td>-0.098214</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>-0.073957</td>\n",
       "      <td>-0.034676</td>\n",
       "      <td>-0.053466</td>\n",
       "      <td>-0.014004</td>\n",
       "      <td>-0.039940</td>\n",
       "      <td>-0.060083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-21</th>\n",
       "      <td>-0.036534</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>-0.060693</td>\n",
       "      <td>-0.051865</td>\n",
       "      <td>-0.100573</td>\n",
       "      <td>-0.038982</td>\n",
       "      <td>-0.001194</td>\n",
       "      <td>-0.015646</td>\n",
       "      <td>-0.048708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070425</td>\n",
       "      <td>-0.042405</td>\n",
       "      <td>-0.095857</td>\n",
       "      <td>-0.015003</td>\n",
       "      <td>-0.041568</td>\n",
       "      <td>-0.019663</td>\n",
       "      <td>-0.049459</td>\n",
       "      <td>-0.025016</td>\n",
       "      <td>-0.034192</td>\n",
       "      <td>-0.110161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-22</th>\n",
       "      <td>-0.089425</td>\n",
       "      <td>-0.035969</td>\n",
       "      <td>0.040912</td>\n",
       "      <td>-0.104488</td>\n",
       "      <td>-0.066286</td>\n",
       "      <td>-0.080632</td>\n",
       "      <td>-0.053136</td>\n",
       "      <td>-0.040657</td>\n",
       "      <td>-0.011120</td>\n",
       "      <td>-0.071381</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099039</td>\n",
       "      <td>-0.037076</td>\n",
       "      <td>-0.082795</td>\n",
       "      <td>-0.073101</td>\n",
       "      <td>-0.063519</td>\n",
       "      <td>-0.060374</td>\n",
       "      <td>-0.059120</td>\n",
       "      <td>-0.020173</td>\n",
       "      <td>-0.028907</td>\n",
       "      <td>-0.151377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-25</th>\n",
       "      <td>-0.066280</td>\n",
       "      <td>-0.028867</td>\n",
       "      <td>-0.050899</td>\n",
       "      <td>-0.079912</td>\n",
       "      <td>-0.038145</td>\n",
       "      <td>-0.088702</td>\n",
       "      <td>-0.041338</td>\n",
       "      <td>-0.036189</td>\n",
       "      <td>-0.003601</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055280</td>\n",
       "      <td>-0.087193</td>\n",
       "      <td>-0.088310</td>\n",
       "      <td>-0.009610</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.055970</td>\n",
       "      <td>-0.029970</td>\n",
       "      <td>-0.013858</td>\n",
       "      <td>-0.031522</td>\n",
       "      <td>0.027071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-26</th>\n",
       "      <td>-0.110785</td>\n",
       "      <td>-0.014059</td>\n",
       "      <td>-0.059108</td>\n",
       "      <td>-0.099518</td>\n",
       "      <td>-0.071680</td>\n",
       "      <td>-0.033733</td>\n",
       "      <td>-0.032256</td>\n",
       "      <td>-0.020683</td>\n",
       "      <td>0.025169</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067825</td>\n",
       "      <td>-0.134928</td>\n",
       "      <td>-0.128378</td>\n",
       "      <td>-0.017705</td>\n",
       "      <td>-0.023730</td>\n",
       "      <td>-0.035957</td>\n",
       "      <td>-0.018647</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.037303</td>\n",
       "      <td>0.047009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-27</th>\n",
       "      <td>0.002977</td>\n",
       "      <td>-0.028652</td>\n",
       "      <td>-0.104546</td>\n",
       "      <td>-0.082745</td>\n",
       "      <td>-0.024902</td>\n",
       "      <td>-0.092571</td>\n",
       "      <td>-0.051298</td>\n",
       "      <td>-0.085182</td>\n",
       "      <td>-0.011571</td>\n",
       "      <td>-0.065788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089327</td>\n",
       "      <td>-0.111786</td>\n",
       "      <td>-0.059352</td>\n",
       "      <td>-0.035927</td>\n",
       "      <td>-0.037049</td>\n",
       "      <td>-0.050367</td>\n",
       "      <td>-0.010416</td>\n",
       "      <td>-0.028947</td>\n",
       "      <td>0.098867</td>\n",
       "      <td>0.044037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-28</th>\n",
       "      <td>-0.070308</td>\n",
       "      <td>-0.075275</td>\n",
       "      <td>-0.065415</td>\n",
       "      <td>-0.063506</td>\n",
       "      <td>-0.002107</td>\n",
       "      <td>-0.048680</td>\n",
       "      <td>-0.037056</td>\n",
       "      <td>0.008441</td>\n",
       "      <td>-0.091162</td>\n",
       "      <td>-0.012202</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082727</td>\n",
       "      <td>-0.071815</td>\n",
       "      <td>-0.073248</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.037938</td>\n",
       "      <td>-0.010275</td>\n",
       "      <td>0.016041</td>\n",
       "      <td>0.081139</td>\n",
       "      <td>-0.023304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-29</th>\n",
       "      <td>-0.021942</td>\n",
       "      <td>-0.058292</td>\n",
       "      <td>-0.142887</td>\n",
       "      <td>-0.175397</td>\n",
       "      <td>-0.042811</td>\n",
       "      <td>-0.017055</td>\n",
       "      <td>-0.039590</td>\n",
       "      <td>-0.097668</td>\n",
       "      <td>-0.085896</td>\n",
       "      <td>-0.025975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055542</td>\n",
       "      <td>-0.077926</td>\n",
       "      <td>-0.079035</td>\n",
       "      <td>0.034105</td>\n",
       "      <td>-0.074416</td>\n",
       "      <td>-0.047872</td>\n",
       "      <td>-0.019248</td>\n",
       "      <td>0.031333</td>\n",
       "      <td>0.089225</td>\n",
       "      <td>0.032765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-01</th>\n",
       "      <td>-0.061708</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>-0.047790</td>\n",
       "      <td>-0.180773</td>\n",
       "      <td>-0.062636</td>\n",
       "      <td>-0.058417</td>\n",
       "      <td>-0.043803</td>\n",
       "      <td>-0.016656</td>\n",
       "      <td>-0.032419</td>\n",
       "      <td>-0.063410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111530</td>\n",
       "      <td>-0.045793</td>\n",
       "      <td>-0.024861</td>\n",
       "      <td>0.051887</td>\n",
       "      <td>-0.109266</td>\n",
       "      <td>-0.076792</td>\n",
       "      <td>-0.034797</td>\n",
       "      <td>-0.054026</td>\n",
       "      <td>-0.026364</td>\n",
       "      <td>0.026330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-02</th>\n",
       "      <td>-0.021130</td>\n",
       "      <td>-0.026613</td>\n",
       "      <td>-0.020720</td>\n",
       "      <td>-0.082383</td>\n",
       "      <td>-0.126417</td>\n",
       "      <td>-0.093461</td>\n",
       "      <td>-0.045779</td>\n",
       "      <td>-0.009832</td>\n",
       "      <td>0.019292</td>\n",
       "      <td>-0.025397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085280</td>\n",
       "      <td>-0.040702</td>\n",
       "      <td>-0.071211</td>\n",
       "      <td>-0.013868</td>\n",
       "      <td>-0.090575</td>\n",
       "      <td>-0.059437</td>\n",
       "      <td>-0.039564</td>\n",
       "      <td>-0.051724</td>\n",
       "      <td>0.073441</td>\n",
       "      <td>0.044914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-03</th>\n",
       "      <td>0.007845</td>\n",
       "      <td>-0.032114</td>\n",
       "      <td>-0.032394</td>\n",
       "      <td>-0.035843</td>\n",
       "      <td>-0.102096</td>\n",
       "      <td>-0.068797</td>\n",
       "      <td>-0.035619</td>\n",
       "      <td>-0.067892</td>\n",
       "      <td>-0.018455</td>\n",
       "      <td>-0.039039</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065059</td>\n",
       "      <td>-0.119800</td>\n",
       "      <td>-0.054162</td>\n",
       "      <td>0.042749</td>\n",
       "      <td>-0.083769</td>\n",
       "      <td>-0.050418</td>\n",
       "      <td>-0.053556</td>\n",
       "      <td>-0.018631</td>\n",
       "      <td>0.049766</td>\n",
       "      <td>0.044596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-04</th>\n",
       "      <td>0.018649</td>\n",
       "      <td>-0.047318</td>\n",
       "      <td>-0.024548</td>\n",
       "      <td>-0.034061</td>\n",
       "      <td>-0.030494</td>\n",
       "      <td>-0.128594</td>\n",
       "      <td>-0.038318</td>\n",
       "      <td>-0.072475</td>\n",
       "      <td>-0.032921</td>\n",
       "      <td>-0.016805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078459</td>\n",
       "      <td>-0.044797</td>\n",
       "      <td>-0.035863</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>-0.078355</td>\n",
       "      <td>-0.085342</td>\n",
       "      <td>-0.020251</td>\n",
       "      <td>0.052192</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>0.022050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05</th>\n",
       "      <td>-0.020690</td>\n",
       "      <td>-0.039884</td>\n",
       "      <td>-0.045705</td>\n",
       "      <td>-0.042608</td>\n",
       "      <td>-0.077543</td>\n",
       "      <td>-0.173207</td>\n",
       "      <td>-0.047142</td>\n",
       "      <td>-0.079641</td>\n",
       "      <td>-0.110355</td>\n",
       "      <td>-0.054400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103695</td>\n",
       "      <td>-0.047740</td>\n",
       "      <td>-0.060797</td>\n",
       "      <td>0.033849</td>\n",
       "      <td>-0.083561</td>\n",
       "      <td>-0.071032</td>\n",
       "      <td>-0.026630</td>\n",
       "      <td>0.100022</td>\n",
       "      <td>0.047328</td>\n",
       "      <td>0.000929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-08</th>\n",
       "      <td>-0.017364</td>\n",
       "      <td>-0.086174</td>\n",
       "      <td>-0.068016</td>\n",
       "      <td>-0.083255</td>\n",
       "      <td>-0.018995</td>\n",
       "      <td>-0.026381</td>\n",
       "      <td>-0.043424</td>\n",
       "      <td>-0.022956</td>\n",
       "      <td>-0.209338</td>\n",
       "      <td>-0.035910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119340</td>\n",
       "      <td>-0.088638</td>\n",
       "      <td>-0.084779</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>-0.107571</td>\n",
       "      <td>-0.084876</td>\n",
       "      <td>-0.073344</td>\n",
       "      <td>0.023437</td>\n",
       "      <td>0.072001</td>\n",
       "      <td>-0.075213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-09</th>\n",
       "      <td>-0.024257</td>\n",
       "      <td>-0.091636</td>\n",
       "      <td>-0.067799</td>\n",
       "      <td>-0.083255</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.004350</td>\n",
       "      <td>-0.051166</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>-0.007369</td>\n",
       "      <td>-0.044589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098483</td>\n",
       "      <td>-0.075084</td>\n",
       "      <td>-0.045894</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>-0.093821</td>\n",
       "      <td>-0.077927</td>\n",
       "      <td>-0.095291</td>\n",
       "      <td>-0.016390</td>\n",
       "      <td>0.054250</td>\n",
       "      <td>-0.140880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-10</th>\n",
       "      <td>-0.019769</td>\n",
       "      <td>-0.119113</td>\n",
       "      <td>-0.030304</td>\n",
       "      <td>-0.066224</td>\n",
       "      <td>-0.006541</td>\n",
       "      <td>-0.043714</td>\n",
       "      <td>-0.040920</td>\n",
       "      <td>-0.076782</td>\n",
       "      <td>-0.033354</td>\n",
       "      <td>-0.004815</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101533</td>\n",
       "      <td>-0.036542</td>\n",
       "      <td>-0.081267</td>\n",
       "      <td>0.024717</td>\n",
       "      <td>0.007554</td>\n",
       "      <td>-0.075204</td>\n",
       "      <td>-0.102495</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>0.024153</td>\n",
       "      <td>-0.125678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-12</th>\n",
       "      <td>-0.023046</td>\n",
       "      <td>-0.090995</td>\n",
       "      <td>-0.053067</td>\n",
       "      <td>-0.084283</td>\n",
       "      <td>-0.014969</td>\n",
       "      <td>0.025695</td>\n",
       "      <td>-0.052937</td>\n",
       "      <td>-0.082406</td>\n",
       "      <td>-0.101377</td>\n",
       "      <td>-0.032168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086362</td>\n",
       "      <td>-0.084299</td>\n",
       "      <td>-0.004144</td>\n",
       "      <td>0.031691</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>-0.101609</td>\n",
       "      <td>-0.144196</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.042997</td>\n",
       "      <td>-0.046863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-15</th>\n",
       "      <td>-0.018064</td>\n",
       "      <td>-0.101336</td>\n",
       "      <td>-0.032785</td>\n",
       "      <td>-0.058098</td>\n",
       "      <td>-0.034124</td>\n",
       "      <td>-0.062682</td>\n",
       "      <td>-0.065539</td>\n",
       "      <td>-0.111538</td>\n",
       "      <td>-0.204170</td>\n",
       "      <td>-0.049036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107144</td>\n",
       "      <td>-0.070232</td>\n",
       "      <td>-0.026734</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.030161</td>\n",
       "      <td>-0.106908</td>\n",
       "      <td>-0.042002</td>\n",
       "      <td>0.014908</td>\n",
       "      <td>0.022478</td>\n",
       "      <td>0.027896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-16</th>\n",
       "      <td>-0.057286</td>\n",
       "      <td>-0.149869</td>\n",
       "      <td>-0.078368</td>\n",
       "      <td>-0.086228</td>\n",
       "      <td>-0.011869</td>\n",
       "      <td>-0.095159</td>\n",
       "      <td>-0.026686</td>\n",
       "      <td>-0.073214</td>\n",
       "      <td>-0.196765</td>\n",
       "      <td>-0.018998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087577</td>\n",
       "      <td>-0.061985</td>\n",
       "      <td>-0.024003</td>\n",
       "      <td>-0.014390</td>\n",
       "      <td>0.039349</td>\n",
       "      <td>-0.100888</td>\n",
       "      <td>-0.091066</td>\n",
       "      <td>0.026240</td>\n",
       "      <td>0.012356</td>\n",
       "      <td>-0.039328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-17</th>\n",
       "      <td>-0.020134</td>\n",
       "      <td>-0.157815</td>\n",
       "      <td>-0.023239</td>\n",
       "      <td>-0.095391</td>\n",
       "      <td>-0.012603</td>\n",
       "      <td>-0.066005</td>\n",
       "      <td>-0.031396</td>\n",
       "      <td>-0.117485</td>\n",
       "      <td>-0.079494</td>\n",
       "      <td>-0.150026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107681</td>\n",
       "      <td>-0.092078</td>\n",
       "      <td>-0.012052</td>\n",
       "      <td>0.055812</td>\n",
       "      <td>0.055997</td>\n",
       "      <td>-0.098149</td>\n",
       "      <td>-0.066285</td>\n",
       "      <td>-0.031150</td>\n",
       "      <td>0.027991</td>\n",
       "      <td>-0.039709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-18</th>\n",
       "      <td>-0.068502</td>\n",
       "      <td>-0.103818</td>\n",
       "      <td>-0.012227</td>\n",
       "      <td>-0.121946</td>\n",
       "      <td>-0.033650</td>\n",
       "      <td>0.031122</td>\n",
       "      <td>-0.110024</td>\n",
       "      <td>-0.098215</td>\n",
       "      <td>-0.025627</td>\n",
       "      <td>-0.057152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108332</td>\n",
       "      <td>-0.117284</td>\n",
       "      <td>-0.029281</td>\n",
       "      <td>0.017015</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>-0.072937</td>\n",
       "      <td>-0.058700</td>\n",
       "      <td>0.008069</td>\n",
       "      <td>-0.039554</td>\n",
       "      <td>0.029926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1332 JT   1605 JT   1721 JT   1801 JT   1802 JT   1803 JT  \\\n",
       "date                                                                     \n",
       "2021-01-04 -0.018939  0.003076  0.008247 -0.027378 -0.075030 -0.116087   \n",
       "2021-01-05  0.002930 -0.006106 -0.060357 -0.029978 -0.110961 -0.036406   \n",
       "2021-01-06 -0.062118 -0.055911 -0.060585 -0.039414 -0.122187 -0.115944   \n",
       "2021-01-07 -0.040547 -0.035640 -0.047727 -0.068679 -0.090097 -0.146940   \n",
       "2021-01-08  0.011170 -0.031788 -0.045364 -0.153280 -0.111649 -0.147236   \n",
       "2021-01-12  0.018327 -0.054434 -0.033760 -0.145032 -0.101840 -0.138109   \n",
       "2021-01-13  0.025242 -0.045809 -0.022087 -0.121981 -0.102348 -0.197406   \n",
       "2021-01-14 -0.001391  0.002470 -0.049412 -0.137831 -0.038430 -0.112005   \n",
       "2021-01-15 -0.016707 -0.095565 -0.025274 -0.133647 -0.071924 -0.114405   \n",
       "2021-01-18 -0.078730 -0.018462 -0.007623 -0.056069 -0.105540 -0.149555   \n",
       "2021-01-19 -0.041826 -0.029179 -0.010371 -0.032611 -0.093590 -0.106185   \n",
       "2021-01-20 -0.073261 -0.078500 -0.015295 -0.044377 -0.093502 -0.084237   \n",
       "2021-01-21 -0.036534 -0.014313  0.002915 -0.060693 -0.051865 -0.100573   \n",
       "2021-01-22 -0.089425 -0.035969  0.040912 -0.104488 -0.066286 -0.080632   \n",
       "2021-01-25 -0.066280 -0.028867 -0.050899 -0.079912 -0.038145 -0.088702   \n",
       "2021-01-26 -0.110785 -0.014059 -0.059108 -0.099518 -0.071680 -0.033733   \n",
       "2021-01-27  0.002977 -0.028652 -0.104546 -0.082745 -0.024902 -0.092571   \n",
       "2021-01-28 -0.070308 -0.075275 -0.065415 -0.063506 -0.002107 -0.048680   \n",
       "2021-01-29 -0.021942 -0.058292 -0.142887 -0.175397 -0.042811 -0.017055   \n",
       "2021-02-01 -0.061708  0.003685 -0.047790 -0.180773 -0.062636 -0.058417   \n",
       "2021-02-02 -0.021130 -0.026613 -0.020720 -0.082383 -0.126417 -0.093461   \n",
       "2021-02-03  0.007845 -0.032114 -0.032394 -0.035843 -0.102096 -0.068797   \n",
       "2021-02-04  0.018649 -0.047318 -0.024548 -0.034061 -0.030494 -0.128594   \n",
       "2021-02-05 -0.020690 -0.039884 -0.045705 -0.042608 -0.077543 -0.173207   \n",
       "2021-02-08 -0.017364 -0.086174 -0.068016 -0.083255 -0.018995 -0.026381   \n",
       "2021-02-09 -0.024257 -0.091636 -0.067799 -0.083255 -0.068345  0.004350   \n",
       "2021-02-10 -0.019769 -0.119113 -0.030304 -0.066224 -0.006541 -0.043714   \n",
       "2021-02-12 -0.023046 -0.090995 -0.053067 -0.084283 -0.014969  0.025695   \n",
       "2021-02-15 -0.018064 -0.101336 -0.032785 -0.058098 -0.034124 -0.062682   \n",
       "2021-02-16 -0.057286 -0.149869 -0.078368 -0.086228 -0.011869 -0.095159   \n",
       "2021-02-17 -0.020134 -0.157815 -0.023239 -0.095391 -0.012603 -0.066005   \n",
       "2021-02-18 -0.068502 -0.103818 -0.012227 -0.121946 -0.033650  0.031122   \n",
       "\n",
       "             1812 JT   1925 JT   1928 JT   1963 JT  ...   9502 JT   9503 JT  \\\n",
       "date                                                ...                       \n",
       "2021-01-04 -0.026987  0.011689  0.003778 -0.026465  ... -0.020225 -0.013980   \n",
       "2021-01-05 -0.065880  0.018989 -0.055861 -0.028884  ... -0.025202 -0.020319   \n",
       "2021-01-06  0.006131  0.010083 -0.010172 -0.010369  ... -0.010587 -0.032077   \n",
       "2021-01-07 -0.046812 -0.033392 -0.010785  0.036078  ... -0.022524 -0.044527   \n",
       "2021-01-08 -0.055404 -0.003504 -0.009088  0.070912  ... -0.048316 -0.057901   \n",
       "2021-01-12 -0.054515 -0.062608 -0.001871  0.004664  ... -0.097554 -0.076369   \n",
       "2021-01-13 -0.046977 -0.059349 -0.002847  0.033383  ... -0.072513 -0.048337   \n",
       "2021-01-14 -0.047107 -0.034325 -0.071045  0.010123  ... -0.060910 -0.060857   \n",
       "2021-01-15 -0.044122 -0.049489 -0.034384  0.015962  ... -0.079636 -0.090742   \n",
       "2021-01-18 -0.061788 -0.102335 -0.090226  0.036020  ... -0.068695 -0.050981   \n",
       "2021-01-19 -0.035366 -0.040441 -0.077071 -0.069582  ... -0.062940 -0.065383   \n",
       "2021-01-20 -0.053176  0.012432 -0.045632 -0.066411  ... -0.113420 -0.043629   \n",
       "2021-01-21 -0.038982 -0.001194 -0.015646 -0.048708  ... -0.070425 -0.042405   \n",
       "2021-01-22 -0.053136 -0.040657 -0.011120 -0.071381  ... -0.099039 -0.037076   \n",
       "2021-01-25 -0.041338 -0.036189 -0.003601  0.018781  ... -0.055280 -0.087193   \n",
       "2021-01-26 -0.032256 -0.020683  0.025169  0.030500  ... -0.067825 -0.134928   \n",
       "2021-01-27 -0.051298 -0.085182 -0.011571 -0.065788  ... -0.089327 -0.111786   \n",
       "2021-01-28 -0.037056  0.008441 -0.091162 -0.012202  ... -0.082727 -0.071815   \n",
       "2021-01-29 -0.039590 -0.097668 -0.085896 -0.025975  ... -0.055542 -0.077926   \n",
       "2021-02-01 -0.043803 -0.016656 -0.032419 -0.063410  ... -0.111530 -0.045793   \n",
       "2021-02-02 -0.045779 -0.009832  0.019292 -0.025397  ... -0.085280 -0.040702   \n",
       "2021-02-03 -0.035619 -0.067892 -0.018455 -0.039039  ... -0.065059 -0.119800   \n",
       "2021-02-04 -0.038318 -0.072475 -0.032921 -0.016805  ... -0.078459 -0.044797   \n",
       "2021-02-05 -0.047142 -0.079641 -0.110355 -0.054400  ... -0.103695 -0.047740   \n",
       "2021-02-08 -0.043424 -0.022956 -0.209338 -0.035910  ... -0.119340 -0.088638   \n",
       "2021-02-09 -0.051166  0.003962 -0.007369 -0.044589  ... -0.098483 -0.075084   \n",
       "2021-02-10 -0.040920 -0.076782 -0.033354 -0.004815  ... -0.101533 -0.036542   \n",
       "2021-02-12 -0.052937 -0.082406 -0.101377 -0.032168  ... -0.086362 -0.084299   \n",
       "2021-02-15 -0.065539 -0.111538 -0.204170 -0.049036  ... -0.107144 -0.070232   \n",
       "2021-02-16 -0.026686 -0.073214 -0.196765 -0.018998  ... -0.087577 -0.061985   \n",
       "2021-02-17 -0.031396 -0.117485 -0.079494 -0.150026  ... -0.107681 -0.092078   \n",
       "2021-02-18 -0.110024 -0.098215 -0.025627 -0.057152  ... -0.108332 -0.117284   \n",
       "\n",
       "             9531 JT   9532 JT   9602 JT   9613 JT   9735 JT   9766 JT  \\\n",
       "date                                                                     \n",
       "2021-01-04 -0.082601 -0.046481  0.030419 -0.002494  0.041968 -0.069077   \n",
       "2021-01-05 -0.077105 -0.043631  0.003488  0.024940  0.000022 -0.066285   \n",
       "2021-01-06 -0.097532 -0.049600  0.005532  0.060582  0.033660 -0.048928   \n",
       "2021-01-07 -0.084286 -0.060937  0.013477 -0.064922  0.000830 -0.024479   \n",
       "2021-01-08 -0.122016 -0.056297 -0.044304 -0.050745 -0.012803  0.023852   \n",
       "2021-01-12 -0.094036 -0.110846  0.062038 -0.051137 -0.002323  0.061398   \n",
       "2021-01-13 -0.096683 -0.045818 -0.010623 -0.101832 -0.023574  0.081042   \n",
       "2021-01-14 -0.098281  0.003828 -0.020077 -0.073202 -0.027342  0.064923   \n",
       "2021-01-15 -0.028470 -0.013592 -0.023055 -0.038585 -0.023277  0.029088   \n",
       "2021-01-18 -0.089447 -0.035517 -0.062368  0.018416 -0.059141 -0.012667   \n",
       "2021-01-19 -0.166454 -0.002429 -0.059364 -0.027810 -0.049476 -0.026287   \n",
       "2021-01-20 -0.098214 -0.001086 -0.073957 -0.034676 -0.053466 -0.014004   \n",
       "2021-01-21 -0.095857 -0.015003 -0.041568 -0.019663 -0.049459 -0.025016   \n",
       "2021-01-22 -0.082795 -0.073101 -0.063519 -0.060374 -0.059120 -0.020173   \n",
       "2021-01-25 -0.088310 -0.009610 -0.040593 -0.055970 -0.029970 -0.013858   \n",
       "2021-01-26 -0.128378 -0.017705 -0.023730 -0.035957 -0.018647  0.004365   \n",
       "2021-01-27 -0.059352 -0.035927 -0.037049 -0.050367 -0.010416 -0.028947   \n",
       "2021-01-28 -0.073248  0.009601 -0.000092 -0.037938 -0.010275  0.016041   \n",
       "2021-01-29 -0.079035  0.034105 -0.074416 -0.047872 -0.019248  0.031333   \n",
       "2021-02-01 -0.024861  0.051887 -0.109266 -0.076792 -0.034797 -0.054026   \n",
       "2021-02-02 -0.071211 -0.013868 -0.090575 -0.059437 -0.039564 -0.051724   \n",
       "2021-02-03 -0.054162  0.042749 -0.083769 -0.050418 -0.053556 -0.018631   \n",
       "2021-02-04 -0.035863  0.032183 -0.078355 -0.085342 -0.020251  0.052192   \n",
       "2021-02-05 -0.060797  0.033849 -0.083561 -0.071032 -0.026630  0.100022   \n",
       "2021-02-08 -0.084779  0.006919 -0.107571 -0.084876 -0.073344  0.023437   \n",
       "2021-02-09 -0.045894  0.001904 -0.093821 -0.077927 -0.095291 -0.016390   \n",
       "2021-02-10 -0.081267  0.024717  0.007554 -0.075204 -0.102495  0.008102   \n",
       "2021-02-12 -0.004144  0.031691  0.002164 -0.101609 -0.144196  0.002974   \n",
       "2021-02-15 -0.026734  0.001997  0.030161 -0.106908 -0.042002  0.014908   \n",
       "2021-02-16 -0.024003 -0.014390  0.039349 -0.100888 -0.091066  0.026240   \n",
       "2021-02-17 -0.012052  0.055812  0.055997 -0.098149 -0.066285 -0.031150   \n",
       "2021-02-18 -0.029281  0.017015  0.003336 -0.072937 -0.058700  0.008069   \n",
       "\n",
       "             9983 JT   9984 JT  \n",
       "date                            \n",
       "2021-01-04 -0.136032  0.029471  \n",
       "2021-01-05 -0.135481  0.039391  \n",
       "2021-01-06 -0.029593  0.058375  \n",
       "2021-01-07 -0.072134  0.067698  \n",
       "2021-01-08 -0.167594  0.066568  \n",
       "2021-01-12 -0.069977 -0.015520  \n",
       "2021-01-13 -0.126414  0.026531  \n",
       "2021-01-14 -0.144499 -0.050415  \n",
       "2021-01-15  0.041788  0.002161  \n",
       "2021-01-18  0.071853  0.056997  \n",
       "2021-01-19 -0.056048 -0.095529  \n",
       "2021-01-20 -0.039940 -0.060083  \n",
       "2021-01-21 -0.034192 -0.110161  \n",
       "2021-01-22 -0.028907 -0.151377  \n",
       "2021-01-25 -0.031522  0.027071  \n",
       "2021-01-26  0.037303  0.047009  \n",
       "2021-01-27  0.098867  0.044037  \n",
       "2021-01-28  0.081139 -0.023304  \n",
       "2021-01-29  0.089225  0.032765  \n",
       "2021-02-01 -0.026364  0.026330  \n",
       "2021-02-02  0.073441  0.044914  \n",
       "2021-02-03  0.049766  0.044596  \n",
       "2021-02-04  0.082331  0.022050  \n",
       "2021-02-05  0.047328  0.000929  \n",
       "2021-02-08  0.072001 -0.075213  \n",
       "2021-02-09  0.054250 -0.140880  \n",
       "2021-02-10  0.024153 -0.125678  \n",
       "2021-02-12  0.042997 -0.046863  \n",
       "2021-02-15  0.022478  0.027896  \n",
       "2021-02-16  0.012356 -0.039328  \n",
       "2021-02-17  0.027991 -0.039709  \n",
       "2021-02-18 -0.039554  0.029926  \n",
       "\n",
       "[32 rows x 203 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_test = pd.DataFrame()\n",
    "price_test = pd.DataFrame()\n",
    "\n",
    "for i in asset_series:\n",
    "    df = pd.DataFrame()\n",
    "    df[['lastprice','volume']] = df_org.loc[i]\n",
    "#     print(lat)\n",
    "#     print(df.index[-1]==last_date)\n",
    "    if (df.index[0]==begin_date)&(df.index[-1]==last_date):\n",
    "        predictions,scores,price = one_asset(i,df,start_date)\n",
    "        pre_test[i] = predictions\n",
    "        price_test[i] = price\n",
    "\n",
    "pre_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6126cb16",
   "metadata": {},
   "source": [
    "Two: traning is adaptive(Need to run for long time, have not tested yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a55cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i, date in enumerate(date_list):\n",
    "    if date > start_date:\n",
    "        index = i\n",
    "        break\n",
    "pre_test = pd.DataFrame()\n",
    "price_test = pd.DataFrame()\n",
    "for date_index in range(index,len(date_list)-20,rebalance_period):\n",
    "    trade_date = date_list[date_index]\n",
    "    print(date_index-index)\n",
    "    for i in asset_series:\n",
    "        df = pd.DataFrame()\n",
    "        df[['lastprice','volume']] = df_org.loc[i]\n",
    "    #     print(lat)\n",
    "    #     print(df.index[-1]==last_date)\n",
    "        if (df.index[0]==begin_date)&(df.index[-1]==last_date):\n",
    "            predictions,scores,price = one_asset(i,df,trade_date)\n",
    "            pre_test[i] = predictions[0:20]\n",
    "            price_test[i] = price[0:20]\n",
    "        \n",
    "pre_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8939ce05",
   "metadata": {},
   "source": [
    "Backtest: Choose the asset with highest scores to construct a equal weight portfolio. The transaction cost is not accurately calcucated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d1f5671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0529475  0.07474049]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_grade = pre_test\n",
    "df_price = price_test\n",
    "# 初始化一个空的DataFrame来存储投资组合和收益\n",
    "portfolio_return = []\n",
    "portfolio = None  # 用于存储上一个周期的投资组合\n",
    "\n",
    "# 设置参数\n",
    "\n",
    "\n",
    "# 开始执行策略\n",
    "for i in range(0, len(df_grade), rebalance_period):\n",
    "    # 选择当前周期的结束日期\n",
    "    period_end = min(i + rebalance_period, len(df_grade))\n",
    "    \n",
    "    # 对当前周期内的grade排序并选择前十\n",
    "    top_assets = df_grade.iloc[i:period_end].mean().nlargest(10).index\n",
    "    \n",
    "    # 如果现有投资组合存在，计算交易费用\n",
    "    if portfolio is not None:\n",
    "        # 计算需要卖出的部分（不在新的前十名中的资产）\n",
    "        sell_assets = portfolio.difference(top_assets)\n",
    "        # 计算需要买入的部分（在新的前十名但不在旧组合中的资产）\n",
    "        buy_assets = top_assets.difference(portfolio)\n",
    "    else:\n",
    "        # 如果是第一个周期，购买所有的前十名资产\n",
    "        buy_assets = top_assets\n",
    "        sell_assets = []\n",
    "    \n",
    "#     计算交易费用\n",
    "#     transaction_costs = df_price.iloc[i:period_end][buy_assets].iloc[0] * transaction_cost\n",
    "#     total_transaction_costs = transaction_costs.sum() * (1/10)\n",
    "#     print(total_transaction_costs)\n",
    "#     print(len(buy_assets))\n",
    "    # 更新投资组合\n",
    "    portfolio = top_assets\n",
    "    \n",
    "    # 计算每个资产的收益，并考虑交易费\n",
    "    asset_returns = (df_price.iloc[period_end-1, df_price.columns.get_indexer(top_assets)] \n",
    "                     / df_price.iloc[i, df_price.columns.get_indexer(top_assets)] - 1) / 10\n",
    "    \n",
    "    # 计算总收益\n",
    "    period_return = asset_returns.sum()/(1+len(buy_assets)*transaction_cost/10)\n",
    "    \n",
    "    # 将收益分配到相应的日期\n",
    "    portfolio_return.append(period_return+1)\n",
    "# print(portfolio_return)\n",
    "# 计算累积收益\n",
    "portfolio_return_cumulative = np.array(portfolio_return).cumprod()-1\n",
    "cumulative_max = (1 + pd.DataFrame(portfolio_return_cumulative)).cummax()\n",
    "drawdown = (1 + portfolio_return_cumulative) - np.array(cumulative_max)\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "# 计算波动率\n",
    "volatility = np.array(portfolio_return).std() * np.sqrt(252/20)\n",
    "\n",
    "# 打印投资组合的累积收益\n",
    "print(portfolio_return_cumulative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a1054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
